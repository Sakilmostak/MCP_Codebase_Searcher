# ==============================================================================
# MCP Codebase Searcher - Environment Configuration Example
# ==============================================================================
# Renaming this file to `.env` allows the MCP Server to automatically load
# these credentials when elaborating on code findings.

# [REQUIRED]
# At least one provider API Key is required if you are not using a local proxy.
OPENAI_API_KEY="your_openai_api_key_here"
# ANTHROPIC_API_KEY="your_anthropic_api_key_here"
# GOOGLE_API_KEY="your_gemini_api_key_here"

# [OPTIONAL]
# Override the default AI Model used by the elaborator sub-agent.
# Default: gemini/gemini-1.5-flash-latest
# LITELLM_MODEL_NAME="gpt-4o"
# LITELLM_MODEL_NAME="ollama/llama3"
# LITELLM_MODEL_NAME="bedrock/anthropic.claude-3-sonnet"

# [OPTIONAL] 
# Override the API Base URL. Essential for using local models like Ollama, 
# LM Studio, vLLM, or corporate proxies.
# LITELLM_API_BASE="http://localhost:11434"